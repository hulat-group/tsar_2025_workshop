# üß† HULAT-UC3M @ TSAR 2025 Shared Task

[![TSAR 2025](https://img.shields.io/badge/TSAR-2025-blue)](https://tsar-workshop.github.io/shared-task/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)]()

---

## üåê Enlace oficial de la tarea
üëâ [TSAR 2025 Shared Task](https://tsar-workshop.github.io/shared-task/)

---

## üë• Equipo

**HULAT-UC3M (Human Language and Accessibility Technologies)**  
Universidad Carlos III de Madrid  

- Paloma Mart√≠nez Fern√°ndez  
- Lourdes Moreno L√≥pez  
- Jes√∫s Manuel S√°nchez G√≥mez  
- Javier Madrid  
- Marco Antonio S√°nchez Escudero  

---

## üìù Resumen del enfoque

Participamos en la tarea **TSAR 2025** utilizando el modelo **Meta LLaMA 3 (8B par√°metros)**, sin fine-tuning adicional, √∫nicamente mediante **estrategias de prompting**.  
Presentamos **dos ejecuciones**:  

- **Run 1: Prompt reforzado**  
  Descripciones detalladas de cada nivel CEFR, gu√≠an al modelo a simplificar los textos indicando expl√≠citamente el nivel de destino.  

- **Run 2: Prompt ligeramente reforzado**  
  Versi√≥n m√°s breve de las descripciones CEFR, buscando balance entre precisi√≥n y concisi√≥n en la simplificaci√≥n.  

---

## ‚öôÔ∏è Uso

```bash
# Ejemplo de inferencia (mock o real si se libera c√≥digo)
python src/inference.py \
  --config configs/run1.yaml \
  --input data/test.jsonl \
  --output runs/run1_predictions.jsonl

# Evaluaci√≥n (m√©tricas SARI, BERTScore, FHRI, SAS‚Ä¶)
python src/evaluate.py \
  --pred runs/run1_predictions.jsonl \
  --refs data/references.jsonl \
  --output results/metrics_run1.csv
